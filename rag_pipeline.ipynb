{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc13Pm-mk1HS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UVlG8R7nyHRE"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eC7jcGVGylQq"
      },
      "outputs": [],
      "source": [
        "api_key = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=api_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZTz1V2T6J6WV"
      },
      "outputs": [],
      "source": [
        "# Load the text file\n",
        "file_path = \"/content/paul_graham_essay.txt\"\n",
        "loader = TextLoader(file_path)\n",
        "documents = loader.load()\n",
        "\n",
        "# Split the text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rZoDltriLCG1"
      },
      "outputs": [],
      "source": [
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "y8MrBqhXLL2b"
      },
      "outputs": [],
      "source": [
        "vector_store = FAISS.from_documents(texts, embeddings).as_retriever(search_type = 'similarity', search_kwargs={\"k\":10})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1rOGZLs-yqkC"
      },
      "outputs": [],
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", google_api_key=api_key, temperature=0, max_tokens=500, request_options={\"timeout\":5000})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HrGzaDz9hTrA"
      },
      "outputs": [],
      "source": [
        "system_prompt = (\n",
        "    \"You arw an assistant for question-answering tasks. \"\n",
        "    \"Use the following pieces of context to answer the question at the end.\"\n",
        "    \" If you don't know the answer, just \"\n",
        "    \"say that you don't know, don't try to make up an answer. Use three sentences maximum and keep\"\n",
        "    \" the answer as concise as possible.\"\n",
        "    \"Always say 'thanks for asking!' at the end of the answer\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"human\",  \"{input}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7cc1eOchlMSN"
      },
      "outputs": [],
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(vector_store, question_answer_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOMboy4cTnm0",
        "outputId": "7a64dd86-1030-42ed-cdc3-5ce724c1fe29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sam Altman was recruited to be the president of Y Combinator, succeeding the founders.  He initially declined the offer, wanting to start a nuclear reactor company. However, he eventually accepted and took over in the winter of 2014. Thanks for asking!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# question = \"What is the main topic of the document?\"\n",
        "question = \"Who was Sam Altman?\"\n",
        "response = rag_chain.invoke({\"input\": question})\n",
        "print(response[\"answer\"], end=\"\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
